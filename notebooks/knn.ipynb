{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis con KNN\n",
    "## Clasificador en C++ üí™üí™\n",
    "Vamos a probar a nuestro bichito\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir los path al ejecutable de python 3.6 y sus librer√≠as,\n",
    "de acuerdo al virtual env que est√©n corriendo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .. && git submodule init\n",
    "!cd .. && git submodule update\n",
    "!cd .. && mkdir build\n",
    "!cd ../build/ && rm -rf *\n",
    "!cd ../build && cmake \\\n",
    "  -DPYTHON_EXECUTABLE=\"$(which python)\" \\\n",
    "  -DCMAKE_BUILD_TYPE=Release ..\n",
    "!cd ../build && make install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifico la correcta instalaci√≥n. Si no falla el import est√° OK\n",
    "!pwd\n",
    "!python --version\n",
    "import sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "\n",
    "!cd ../data && tar -xvf *.tgz\n",
    "\n",
    "df = pd.read_csv(\"../data/imdb_small.csv\", index_col=0)\n",
    "\n",
    "print(\"Cantidad de documentos: {}\".format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = df[df.type == 'train'][\"review\"]\n",
    "label_train = df[df.type == 'train'][\"label\"]\n",
    "\n",
    "text_test = df[df.type == 'test'][\"review\"]\n",
    "label_test = df[df.type == 'test'][\"label\"]\n",
    "\n",
    "#descomentar esto si se quiere tener un dataset m√°s chico que los 6.000 totales\n",
    "#text_train = text_train[:1000]\n",
    "#label_train = label_train[:1000]\n",
    "\n",
    "#text_test = text_test[:1000]\n",
    "#label_test = label_test[:1000]\n",
    "\n",
    "print(\"Cantidad de instancias de entrenamiento = {}\".format(len(text_train)))\n",
    "print(\"Cantidad de instancias de test = {}\".format(len(text_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "print(\"Class balance : {} pos {} neg\".format(\n",
    "    (label_train == 'pos').sum() / label_train.shape[0], \n",
    "    (label_train == 'neg').sum() / label_train.shape[0]\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=0.90, min_df=0.01, max_features=5000)\n",
    "#max df cambia muy poco, hay muy pocas palabras que aparecen m√°s de 80% de los comentarios por ej\n",
    "#incluso m√°s que en el 20% de los comentarios no hay muchas, igual tiene sentido hacerlo quizas? para sacar molestos.\n",
    "#Seguro no quiero un max_df bajo como 0.20 porque me saca las mejores palabras para comparar..\n",
    "#Probar si poner max_df=0.1 por ej arruina PCA\n",
    "\n",
    "#min_df=0.003 es el momento clave que max_features se acerca a 5000. O sea que hay como 4800 palabras que aparecen en 0.3% comentarios\n",
    "#ya con min_df=0.01% tenemos como 43.000 palabras. Todas las palabras aparecen en al menos 0.01% de comments?? es raro eso\n",
    "#Duh.. 0.01% ya es menos de 1 comentario.. Podr√≠a pensar que el m√°ximo razonable para probar de min_df es 0.2%, que es aparecer\n",
    "#en 12 comentarios aprox, que podemos pensar empieza a ser suficiente para sacar conclusiones.\n",
    "#Eso ya te baja el N¬∫ palabras a 6500, que es bastante cerca del m√°ximo que quer√≠amos tomar de 5000. Experimentar por ah√≠\n",
    "\n",
    "#OJO, count vectorizer solo nos deja 43.000 palabras, que son todas las que hay en text_train, y al text_test lo reduce\n",
    "#a esas palabras!!! o sea que ni cuenta las palabras que hay en los comentarios de test que no estaban en el train\n",
    "\n",
    "#para los valores que ven√≠a por defecto de la catedra (0.9  0.01):\n",
    "#segun esto, los comentarios de train quedan en promedio con 102 palabras, y los de test con 98, no es terrible, pero claramente\n",
    "#les sacamos varias palabras a los de train... igualmente seguro eran las menos frecuentes, porque nunca aparecian en train\n",
    "\n",
    "vectorizer.fit(text_train)\n",
    "\n",
    "X_train, y_train = vectorizer.transform(text_train), (label_train == 'pos').values\n",
    "X_test, y_test = vectorizer.transform(text_test), (label_test == 'pos').values\n",
    "\n",
    "#esto te deja ver cuantas palabras quedaron despues del CountVectorizer\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentiment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar;\n",
    "import time;\n",
    "\n",
    "def f1score(prec, rec):\n",
    "    f1 = 2*(prec*rec)/(prec+rec)\n",
    "    return f1\n",
    "\n",
    "def getMetrics(predictions, actualValues):\n",
    "    tp = np.sum( np.logical_and(predictions == 1, actualValues == 1) )\n",
    "    tn = np.sum( np.logical_and(predictions == 0, actualValues == 0) )\n",
    "    fp = np.sum( np.logical_and(predictions == 1, actualValues == 0) )\n",
    "    fn = np.sum( np.logical_and(predictions == 0, actualValues == 1) )\n",
    "\n",
    "    acc = (tp + tn) / (tp+tn+fp+fn)\n",
    "    if (tp + fp) == 0:\n",
    "        #esto es que nunca predije que algo era positivo, o sea que nunca le pifi√©\n",
    "        prec = 1\n",
    "    else:\n",
    "        prec = tp / (tp + fp)\n",
    "    if (tp + fn) == 0:\n",
    "        #esto es que no hab√≠a positivos reales, o sea que \"los agarr√© a todos\"\n",
    "        rec = 1\n",
    "    else:\n",
    "        rec = tp / (tp + fn)\n",
    "    return acc, prec, rec\n",
    "\n",
    "def saveData(filename, data):\n",
    "    ts = calendar.timegm(time.gmtime())\n",
    "    np.savetxt(\"{}_{}.csv\".format(ts, filename), data, delimiter=\",\")\n",
    "    \n",
    "print(\"Done! You're a good boy üê∂\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Esta celda puede ser ejecutada s√≥lo cuando se quiere probar PCA\n",
    "pca = sentiment.PCA(50)\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Idem anterior!\n",
    "\n",
    "pca_x_train = pca.transform(X_train)\n",
    "pca_x_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Descomentar la implementaci√≥n deseada:\n",
    "# Uncomment this for KNN only (PCA disabled):\n",
    "# clf = sentiment.KNNClassifier(100)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = clf.predict(X_test[:500])\n",
    "# acc = accuracy_score(y_test[:500], y_pred[:500])\n",
    "\n",
    "# Uncomment this for PCA enabled:\n",
    "clf = sentiment.KNNClassifier(550)\n",
    "clf.fit(pca_x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(pca_x_test)\n",
    "\n",
    "acc, prec, rec = getMetrics(y_pred, y_test)\n",
    "f1 = f1score(prec, rec)\n",
    "\n",
    "print(acc, prec, rec, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ==================== Experimento 1 ========================\n",
    "## An√°lisis de calidad de resultados en base a k y alpha\n",
    "\n",
    "## Analizo la variaci√≥n de las m√©tricas en funcion de k\n",
    "\n",
    "K_vals = np.arange(0,500,25)\n",
    "K_vals[0] = 1\n",
    "mets = np.zeros((len(K_vals), 3))\n",
    "               \n",
    "for i,a in enumerate(K_vals):\n",
    "    pca = sentiment.PCA(a)\n",
    "    pca.fit(X_train[:1000])\n",
    "    Xtc_train = pca.transform(X_train[:1000])\n",
    "    Xtc_test = pca.transform(X_test[:1000])\n",
    "    \n",
    "    clf = sentiment.KNNClassifier(25)\n",
    "    clf.fit(Xtc_train, y_train[:1000])\n",
    "    preds = clf.predict(Xtc_test)\n",
    "    acc, prec, rec = getMetrics(preds[:1000], y_test[:1000])\n",
    "    f1 = f1score(prec, rec)\n",
    "    mets[i] = [acc, prec, rec, f1]\n",
    "    print(\"Finished {}\".format(a))\n",
    "    \n",
    "plt.plot(K_vals,mets[:,0], 'b.-')\n",
    "plt.plot(K_vals,mets[:,1], 'r.-')\n",
    "plt.plot(K_vals,mets[:,2], 'g.-')\n",
    "plt.plot(K_vals,mets[:,3], 'k.-')\n",
    "plt.title(\"Metricas en funcion de Alpha\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"%\")\n",
    "plt.axis([1, K_vals[-1], 0.4, 1])\n",
    "plt.gca().legend(('Acc','Prec','Recall','F1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analizo la variaci√≥n de las m√©tricas en funcion de alpha para K fijo\n",
    "\n",
    "alphas = np.arange(0,500,50)\n",
    "alphas[0] = 1\n",
    "K_vals_fixes = np.array([50,550,1100])\n",
    "\n",
    "dmets = { i : np.zeros((len(alphas), 3)) for i in K_vals_fixes}\n",
    "dmets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Beginning alpha metric calculations\")\n",
    "\n",
    "for i,a in enumerate(alphas):\n",
    "    \n",
    "    pca = sentiment.PCA(a)\n",
    "    pca.fit(X_train)\n",
    "    Xtc_train = pca.transform(X_train)\n",
    "    Xtc_test = pca.transform(X_test)\n",
    "    print(\"Finished training PCA {}\".format(a))\n",
    "\n",
    "    for j, k in enumerate(K_vals_fixes):\n",
    "        clf = sentiment.KNNClassifier(k)\n",
    "        clf.fit(Xtc_train, y_train)\n",
    "        preds = clf.predict(Xtc_test)\n",
    "        acc, prec, rec = getMetrics(preds, y_test)\n",
    "        f1 = f1score(prec,rec)\n",
    "        mets = dmets[k]\n",
    "        mets[i] = [acc, prec, rec, f1]\n",
    "        print(\"Finished {}, alpha = {}\".format(k, a))\n",
    "\n",
    "\n",
    "## Metricas para PCA:\n",
    "\n",
    "line_styles = ['b.-', 'r.-', 'g.-', 'k.-', 'y.-', 'm.-']\n",
    "for j,k in enumerate(K_vals_fixes):\n",
    "    mets = dmets[k]\n",
    "\n",
    "    plt.subplot(4, 1, 1)\n",
    "    plt.plot(alphas,mets[:,0], line_styles[j])\n",
    "    plt.ylabel(\"Acc\")\n",
    "    plt.xticks([])\n",
    "\n",
    "    plt.subplot(4, 1, 2)\n",
    "    plt.plot(alphas,mets[:,1], line_styles[j])\n",
    "    plt.ylabel(\"Prec\")\n",
    "    plt.xticks([])\n",
    "    \n",
    "    plt.subplot(4, 1, 3)\n",
    "    plt.plot(alphas,mets[:,2], line_styles[j])\n",
    "    plt.ylabel(\"Rec\")\n",
    "    plt.xticks([])\n",
    "    \n",
    "    plt.subplot(4, 1, 4)\n",
    "    plt.plot(alphas,mets[:,2], line_styles[j])\n",
    "    plt.ylabel(\"F1\")\n",
    "    plt.xticks([])\n",
    "\n",
    "    \n",
    "plt.xlabel(\"alpha\")\n",
    "plt.xticks(alphas)\n",
    "plt.axis([1, alphas[-1], 0.3, 0.8])\n",
    "plt.gca().legend([str(i) for i in K_vals_fixes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.random((1200, 500))\n",
    "\n",
    "# generate 2 2d grids for the x & y bounds\n",
    "y, x = np.meshgrid(np.linspace(-1, 1200), np.linspace(1, 500))\n",
    "\n",
    "z = (1 - x / 2. + x ** 5 + y ** 3) * np.exp(-x ** 2 - y ** 2)\n",
    "# x and y are bounds, so z should be the value *inside* those bounds.\n",
    "# Therefore, remove the last value from the z array.\n",
    "z_min, z_max = -np.abs(z).max(), np.abs(z).max()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "c = ax.pcolormesh(x, y, z, cmap='RdBu', vmin=z_min, vmax=z_max)\n",
    "ax.set_title('pcolormesh')\n",
    "# set the limits of the plot to the limits of the data\n",
    "ax.axis([x.min(), x.max(), y.min(), y.max()])\n",
    "fig.colorbar(c, ax=ax)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(a, cmap='hot', interpolation='nearest')\n",
    "# plt.show()\n",
    "dmets\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15, 0, -1): # <--Delete me\n",
    "    print(i)\n",
    "    pca = sentiment.PCA(min(i, 50))\n",
    "    pca.fit(X_train[:i])\n",
    "    Xtc_train = pca.transform(X_train[:i])\n",
    "    Ytc_train = y_train[:i]\n",
    "    Xtc_test = pca.transform(X_test)\n",
    "    \n",
    "    for k in range(min(i, 50), 0, -1): # <--Delete me\n",
    "        clf = sentiment.KNNClassifier(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSizeRange = range(X_train.shape[0], 0, -120)\n",
    "trainSizeRangeLength = len(trainSizeRange)\n",
    "knnRange = range(2500, 0, -50)\n",
    "knnRangeLength = len(knnRange)\n",
    "\n",
    "print(\"Will have {} trainSize instances\".format(trainSizeRangeLength))\n",
    "print(\"Will have {} knn instances\".format(knnRangeLength))\n",
    "\n",
    "accColorMap = np.zeros(shape=(trainSizeRangeLength, len(knnRange)))\n",
    "precColorMap = np.zeros(shape=(trainSizeRangeLength, len(knnRange)))\n",
    "recColorMap = np.zeros(shape=(trainSizeRangeLength, len(knnRange)))\n",
    "\n",
    "for i in range(0, len(trainSizeRange)):\n",
    "    trainSize = trainSizeRange[i]\n",
    "    pca = sentiment.PCA(min(i, 50))\n",
    "    pca.fit(X_train[:trainSize])\n",
    "    Xtc_train = pca.transform(X_train[:trainSize])\n",
    "    Ytc_train = y_train[:trainSize]\n",
    "    Xtc_test = pca.transform(X_test)\n",
    "    print(\"Finished training PCA train_size = {}\".format(trainSize))\n",
    "\n",
    "    for j in range(0, knnRangeLength):\n",
    "        k = knnRange[j]\n",
    "        if (k <= trainSize):\n",
    "            clf = sentiment.KNNClassifier(k)\n",
    "            clf.fit(Xtc_train, Ytc_train)\n",
    "            preds = clf.predict(Xtc_test)\n",
    "            acc, prec, rec = getMetrics(preds, y_test)\n",
    "            f1 = f1score(prec,rec)\n",
    "            accColorMap[trainSizeRangeLength - i - 1, knnRangeLength - j - 1] = acc\n",
    "            precColorMap[trainSizeRangeLength - i - 1, knnRangeLength - j - 1] = prec\n",
    "            recColorMap[trainSizeRangeLength - i - 1, knnRangeLength - j - 1] = rec\n",
    "            f1ColorMap[trainSizeRangeLength - i - 1, knnRangeLength - j - 1] = f1\n",
    "            print(\"Finished k = {}, train_size = {}\".format(k, trainSize))\n",
    "        else:\n",
    "            accColorMap[trainSizeRangeLength - i - 1, knnRangeLength - j - 1] = 0\n",
    "            precColorMap[trainSizeRangeLength - i - 1, knnRangeLength - j - 1] = 0\n",
    "            recColorMap[trainSizeRangeLength - i - 1, knnRangeLength - j - 1] = 0\n",
    "            f1ColorMap[trainSizeRangeLength - i - 1, knnRangeLength - j - 1] = 0\n",
    "\n",
    "saveData(\"accColorMap\", accColorMap)\n",
    "saveData(\"precColorMap\", precColorMap)\n",
    "saveData(\"recColorMap\", recColorMap)\n",
    "saveData(\"f1ColorMap\", f1ColorMap)\n",
    "        \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "c = ax.pcolormesh(accColorMap, cmap='hot')\n",
    "ax.set_title('Train_size vs neighbors')\n",
    "# set the limits of the plot to the limits of the data\n",
    "ax.axis([0, accColorMap.shape[1], 0, accColorMap.shape[0]])\n",
    "fig.colorbar(c, ax=ax)\n",
    "\n",
    "fig2, ax2 = plt.subplots()\n",
    "\n",
    "c2 = ax2.pcolormesh(precColorMap, cmap='hot')\n",
    "ax2.set_title('pcolormesh')\n",
    "# set the limits of the plot to the limits of the data\n",
    "ax2.axis([0, precColorMap.shape[1], 0, precColorMap.shape[0]])\n",
    "fig2.colorbar(c2, ax=ax2)\n",
    "\n",
    "fig3, ax3 = plt.subplots()\n",
    "\n",
    "c3 = ax3.pcolormesh(recColorMap, cmap='hot')\n",
    "ax3.set_title('pcolormesh')\n",
    "# set the limits of the plot to the limits of the data\n",
    "ax3.axis([0, recColorMap.shape[1], 0, recColorMap.shape[0]])\n",
    "fig3.colorbar(c3, ax=ax3)\n",
    "\n",
    "fig4, ax4 = plt.subplots()\n",
    "\n",
    "c4 = ax4.pcolormesh(f1ColorMap, cmap='hot')\n",
    "ax4.set_title('pcolormesh')\n",
    "# set the limits of the plot to the limits of the data\n",
    "ax4.axis([0, f1ColorMap.shape[1], 0, f1ColorMap.shape[0]])\n",
    "fig4.colorbar(c4, ax=ax4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "c = ax.pcolormesh(accColorMap, cmap='hot', vmin=0, vmax=1)\n",
    "ax.set_title('Train_size vs neighbors (accuracy)')\n",
    "# set the limits of the plot to the limits of the data\n",
    "ax.axis([0, accColorMap.shape[1], 0, accColorMap.shape[0]])\n",
    "ax.set_xlabel(\"Train size (1:125)\")\n",
    "ax.set_ylabel(\"K neighbors (1:50)\")\n",
    "fig.colorbar(c, ax=ax)\n",
    "\n",
    "fig2, ax2 = plt.subplots()\n",
    "\n",
    "c2 = ax2.pcolormesh(precColorMap, cmap='hot', vmin=0, vmax=1)\n",
    "ax2.set_title('Train_size vs neighbors (precision)')\n",
    "# set the limits of the plot to the limits of the data\n",
    "ax2.axis([0, precColorMap.shape[1], 0, precColorMap.shape[0]])\n",
    "ax2.set_xlabel(\"Train size (1:125)\")\n",
    "ax2.set_ylabel(\"K neighbors (1:50)\")\n",
    "fig2.colorbar(c2, ax=ax2)\n",
    "\n",
    "fig3, ax3 = plt.subplots()\n",
    "\n",
    "c3 = ax3.pcolormesh(recColorMap, cmap='hot', vmin=0, vmax=1)\n",
    "ax3.set_title('Train_size vs neighbors (recall)')\n",
    "# set the limits of the plot to the limits of the data\n",
    "ax3.axis([0, recColorMap.shape[1], 0, recColorMap.shape[0]])\n",
    "ax3.set_xlabel(\"Train size (1:125)\")\n",
    "ax3.set_ylabel(\"K neighbors (1:50)\")\n",
    "fig3.colorbar(c3, ax=ax3)\n",
    "\n",
    "fig3, ax3 = plt.subplots()\n",
    "\n",
    "c4 = ax4.pcolormesh(f1ColorMap, cmap='hot', vmin=0, vmax=1)\n",
    "ax4.set_title('Train_size vs neighbors (f1)')\n",
    "# set the limits of the plot to the limits of the data\n",
    "ax4.axis([0, f1ColorMap.shape[1], 0, f1ColorMap.shape[0]])\n",
    "ax4.set_xlabel(\"Train size (1:125)\")\n",
    "ax4.set_ylabel(\"K neighbors (1:50)\")\n",
    "fig4.colorbar(c4, ax=ax4)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
